{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do Uczenia Maszynowego - Lab 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wszystkie dzisiejsze metody można znaleźć dokładnie (i przystępnie!) omówione na StatQuest: https://www.youtube.com/user/joshstarmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.256846Z",
     "start_time": "2020-03-23T09:42:15.442652Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "np.random.seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLOR = 'white'\n",
    "matplotlib.rcParams['text.color'] = COLOR\n",
    "matplotlib.rcParams['axes.labelcolor'] = COLOR\n",
    "matplotlib.rcParams['xtick.color'] = COLOR\n",
    "matplotlib.rcParams['ytick.color'] = COLOR\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['font.size'] = 14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.281787Z",
     "start_time": "2020-03-23T09:42:16.261833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11  Present     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61   Absent     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28  Present     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03  Present     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78  Present     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.288795Z",
     "start_time": "2020-03-23T09:42:16.283777Z"
    }
   },
   "outputs": [],
   "source": [
    "y = np.array(data['chd'])\n",
    "X = data.drop(['chd'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T09:42:16.304107Z",
     "start_time": "2020-03-23T09:42:16.291084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age\n",
       "0  160    12.00  5.73      23.11        1     49    25.30    97.20   52\n",
       "1  144     0.01  4.41      28.61        0     55    28.87     2.06   63\n",
       "2  118     0.08  3.48      32.28        1     52    29.14     3.81   46\n",
       "3  170     7.50  6.41      38.03        1     51    31.99    24.26   58\n",
       "4  134    13.60  3.50      27.78        1     60    25.99    57.34   49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_dict = {'Present': 1, 'Absent':0}\n",
    "X['famhist'] = X['famhist'].map(map_dict)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Methods - Komitety\n",
    "Często kilka osób, które myślą nad daną sprawą, potrafi dać lepszą odpowiedź niż jedna osoba. Nawet jeśli żadna z osób nie jest ekspertem.  \n",
    "To podejście zadziała, gdy błędny popełniane przez różne modele są od siebie niezależne (w miarę). \n",
    "\n",
    "  \n",
    "Na potrzeby stosowania różnych metod Ensemble Learningu załadujemy sobie już 3 modele z których będziemy potem korzystać."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:04:23.248656Z",
     "start_time": "2020-03-23T10:04:23.241676Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = DecisionTreeClassifier(max_depth = 10, random_state=1)\n",
    "model2 = KNeighborsClassifier()\n",
    "model3 = LogisticRegression(random_state=1, max_iter=1000)\n",
    "estimators=[('DecisionTree', model1), ('KNN', model2), ('LR', model3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# czy coś tu nie gra?\n",
    "\n",
    "# @conclusions\n",
    "# nie wiemy do jakich danych\n",
    "# max_depth dla tree nie jest zdefiniowane domyślnie, więc na 90% overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634408602150538"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=1, max_iter=1000)\n",
    "model_lr.fit(X_train, y_train)\n",
    "model_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7012877 , 0.2987123 ],\n",
       "       [0.75003096, 0.24996904],\n",
       "       [0.14134935, 0.85865065],\n",
       "       [0.49614457, 0.50385543],\n",
       "       [0.69339818, 0.30660182],\n",
       "       [0.60127493, 0.39872507],\n",
       "       [0.76427284, 0.23572716],\n",
       "       [0.54772816, 0.45227184],\n",
       "       [0.4603363 , 0.5396637 ],\n",
       "       [0.40133013, 0.59866987]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.predict_proba(X_test)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Voting\n",
    "lub Hard Voting - głosowanie większościowe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:04:23.752520Z",
     "start_time": "2020-03-23T10:04:23.748530Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:04:24.077640Z",
     "start_time": "2020-03-23T10:04:24.044296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7311827956989247\n",
      "model.score:  0.7311827956989247\n"
     ]
    }
   ],
   "source": [
    "model_hard = VotingClassifier(estimators=estimators, voting='hard')\n",
    "model_hard.fit(X_train,y_train)\n",
    "\n",
    "y_hat = model_hard.predict(X_test)\n",
    "print('accuracy: ', accuracy_score(y_test, y_hat))\n",
    "\n",
    "# model też ma metodę ewaluacji i jest to też accuracy w przypadku klasyfikacji\n",
    "print('model.score: ', model_hard.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging\n",
    "Soft Voting. Nie patrzymy na liczbę głosów, ale na \"pewność\". Patrzymy na ile pewny jest klasyfikator, że rekord należy do klasy 1.   \n",
    "c1 - 90%, c2 - 49%, c3 - 49% \n",
    "* hard voting: klasa 0 (1 głos na tak, 2 głosy na nie)\n",
    "* soft voting: klasa 1 ( (90 + 49 + 49)/3 $\\approx$ 63% > 50%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6344086021505376"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_soft = VotingClassifier(estimators=estimators, voting='soft')\n",
    "model_soft.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model_soft.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights\n",
    "Nie musimy zawsze uważać, że każdy klasyfikator ma tyle samo do powiedzenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7526881720430108"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_soft = VotingClassifier(estimators=estimators, voting='soft', weights=[0.05, 0.05, 0.90])\n",
    "model_soft.fit(X_train, y_train)\n",
    "\n",
    "y_hat = model_soft.predict(X_test)\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "<div>\n",
    "<img src=\"https://miro.medium.com/max/700/1*RP0pkQEOSrw9_EjFu4w3gg.png\" />\n",
    "</div>\n",
    "sos: https://miro.medium.com/max/700/1*RP0pkQEOSrw9_EjFu4w3gg.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bierzemy kilka różnych modeli (base) i jeden meta-model. Meta-model uczy się przewidywać wynik na podstawie predykcji z base.\n",
    "\n",
    "Czy można stackować kilka takich samych modeli?  \n",
    " \n",
    "@conclusions  \n",
    "No raczej nie, bo wyniki modeli w base powinny być od siebie niezależne.  \n",
    "Stackowanie jeden na drugim tych samych modeli -> check\n",
    "\n",
    "Zasada kciuka: ostatni model jest raczej prosty (regresja liniowa/logistyczna).  \n",
    "Więcej (np. o trenowaniu) tutaj: https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:05:20.908643Z",
     "start_time": "2020-03-23T10:05:20.904653Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:05:21.255832Z",
     "start_time": "2020-03-23T10:05:21.177931Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7849462365591398"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = StackingClassifier(estimators=[('lr', model3)], final_estimator=LogisticRegression())\n",
    "clf2.fit(X_train, y_train).score(X_test, y_test) - model_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging (Bootstrap Aggregating)\n",
    "Bootstrap - to technika próbkowania, w której tworzymy podzbiory (próby) obserwacji z oryginalnego datasetu, **ze zwracaniem**. Rozmiar podzbiorów jest taki sam jak rozmiar oryginalnego datasetu.\n",
    "\n",
    "1. Losujemy N **bootstrapowych** prób ze zbioru treningowego\n",
    "2. Trenujemy niezależnie N \"słabych\" klasyfikatorów\n",
    "3. Składamy wyniki \"słabych\" modeli \n",
    "    - **Klasyfikacja:** reguła większościowa / uśrednione prawdopodobieństwo\n",
    "    - **Regresja:** Uśrednione wartości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:09:09.734084Z",
     "start_time": "2020-03-23T10:09:09.729082Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:40:53.981479Z",
     "start_time": "2020-03-23T10:40:53.956920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_estimator=model1,\n",
    "                        n_estimators=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "Najbardziej popularny algorytm Baggingowy. Wiele małych drzew.\n",
    "\n",
    "Przypomnijmy\n",
    "#### Zalety drzew\n",
    "* interpretowalność\n",
    "* prostota + wizualizacja\n",
    "* nie trzeba normalizować danych \\:) i outliery się ich nie tykają\n",
    "* mają fajne metody do wykrywania ważnych cech\n",
    "\n",
    "#### Wady drzew\n",
    "* łatwo o overfitting\n",
    "* drzewo długo rośnie\n",
    "* starych drzew się nie przesadza - nie da się dotrenować algorytmu po jakimś czasie, trzeba zasadzić nowe \n",
    "* jest duża losowość - na tych samych danych algorytm może dawać bardzo różne wyniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastanówmy się nad zaletami RF  \n",
    "@conclusions  \n",
    "\n",
    "#### Zalety:\n",
    "* trudniej o overfitting\n",
    "* mają fajne metody do wykrywania ważnych cech\n",
    "* nie trzeba normalizować danych \\:) i outliery się ich nie tykają\n",
    "* mniejsza losowość\n",
    "\n",
    "#### Wady:\n",
    "* las rośnie dłużej niż drzewo\n",
    "* lasu też się nie przesadza\n",
    "* tracimy interpretowalność\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:40:19.674175Z",
     "start_time": "2020-03-23T10:40:19.670184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7634408602150538"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model_rf = RandomForestClassifier(n_estimators=1000, # Ilość słabych estymatorów\n",
    "                                  max_depth=5, # Maksymalna wysokość drzewa w słabym estymatorze\n",
    "                                  min_samples_split = 2, # Minimalna ilość obserwacji wymagana do podziału węzła\n",
    "                                  max_features = 5, # Maksymalna ilość zmiennych brana pod uwagę przy podziale węzła\n",
    "                                  random_state=0,\n",
    "                                  n_jobs = -1)\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_rf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "Boosting działa podobnie jak Bagging z jedną różnicą. Każda kolejna próba bootstrap jest tworzona w taki sposób,  \n",
    "że losuje z większym prawdopodobieństwiem obserwacje **źle sklasyfikowane**.  \n",
    "W skrócie: Boosting uczy się na błędach, które popełnił w poprzednich iteracjach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost\n",
    "Najprostsza metoda boostingowa.  \n",
    "Budujemy wiele bardzo niskich drzew, np. wysokości 1.  \n",
    "Modele, które sobie radzą lepiej, mają większe prawo głosu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:50:26.312390Z",
     "start_time": "2020-03-23T10:50:26.308376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7741935483870968"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(random_state=1, n_estimators=20, learning_rate=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "Zaczynamy od pojedynczej predykcji (np. średniej) i liczymy różnicę, tzw. residuum.  \n",
    "Następnie każdy model (niskie drzewo, niekoniecznie wysokości 1) próbuje przewidzieć residuum.  \n",
    "W GB każdy model ma taki sam głos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:50:44.448951Z",
     "start_time": "2020-03-23T10:50:44.444975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7204301075268817"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=1,\n",
    "                                  learning_rate=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost\n",
    "Zaawansowana implementacja Gradient Boostingu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T10:51:55.997278Z",
     "start_time": "2020-03-23T10:51:55.993198Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier # Inna paczka niż sklearn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T12:45:09.842895Z",
     "start_time": "2020-03-23T12:45:09.783537Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:18:01] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { nround } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[17:18:01] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/igro_m23/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7526881720430108"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=XGBClassifier(random_state=1,\n",
    "                    learning_rate=0.01, # Szybkość \"uczenia\" się\n",
    "                    booster='gbtree', # Jaki model wykorzystujemy (drzewo - gbtree, liniowe - gblinear)\n",
    "                    nround = 100, # Ilość itereacji boosingowych\n",
    "                    max_depth=4 # Maksymalna głębokość drzewa \n",
    "                    )\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wszystkie dzisiejsze metody można znaleźć dokładnie (i przystępnie!) omówione na StatQuest: https://www.youtube.com/user/joshstarmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mateuszgrzyb.pl/wybor-odpowiedniego-algorytmu-czesc-2-algorytmy-klasyfikacyjne/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
