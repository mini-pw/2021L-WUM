{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "## Milestone 2\n",
    "\n",
    "### Dominik Pawlak, Przemysław Olender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import category_encoders as ce\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statistics import stdev\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = pd.read_csv('school_grades_dataset.csv')\n",
    "\n",
    "print(grades_df.shape)\n",
    "grades_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja liniowa dla G1 i G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (12, 5))\n",
    "\n",
    "sns.scatterplot(data = grades_df, x = 'G1', y = 'G3', ax = ax1)\n",
    "sns.scatterplot(data = grades_df, x = 'G2', y = 'G3', ax = ax2)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# liniowa zalezcnosc miedzy G1, G2, i G3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sprawdźmy jak sprawdzi się prsoty model regresji liniowej dla G1, G2 oraz G1 i G2 jednocześnie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = grades_df[['G1']]\n",
    "Y = grades_df['G3']\n",
    "\n",
    "model1 = LinearRegression()\n",
    "X1_train, X1_test, Y1_train, Y1_test = train_test_split(X1, Y, test_size = 0.3, random_state = 1)\n",
    "model1.fit(X1_train, Y1_train)\n",
    "Y1_test_predicted = model1.predict(X1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X1_test, Y1_test, label = 'testing data')\n",
    "plt.plot(X1_test, Y1_test_predicted, label = 'prediction', linewidth = 3, color = 'red')\n",
    "plt.xlabel('G1')\n",
    "plt.ylabel('G3')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE: {mean_squared_error(Y1_test, Y1_test_predicted, squared = False)}')\n",
    "print(f'R-squared: {model1.score(X1_test, Y1_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = grades_df[['G2']]\n",
    "model2 = LinearRegression()\n",
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(X2, Y, test_size = 0.3, random_state = 1)\n",
    "model2.fit(X2_train, Y2_train)\n",
    "Y2_test_predicted = model2.predict(X2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X2_test, Y2_test, label = 'testing data')\n",
    "plt.plot(X2_test, Y2_test_predicted, label = 'prediction', linewidth = 3, color = 'red')\n",
    "plt.xlabel('G2')\n",
    "plt.ylabel('G3')\n",
    "plt.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE: {mean_squared_error(Y2_test, Y2_test_predicted, squared = False)}')\n",
    "print(f'R-squared: {model2.score(X2_test, Y2_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = grades_df[['G1', 'G2']]\n",
    "model3 = LinearRegression()\n",
    "X3_train, X3_test, Y3_train, Y3_test = train_test_split(X3, Y, test_size = 0.3, random_state = 1)\n",
    "model3.fit(X3_train, Y3_train)\n",
    "Y3_test_predicted = model3.predict(X3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE: {mean_squared_error(Y3_test, Y3_test_predicted, squared = False)}')\n",
    "print(f'R-squared: {model3.score(X3_test, Y3_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najlepeij wypadła regresja oparta na G1 i G2, model oparty tylko na G2 jest minimalnie gorszy, najsłabeij prezentuje się model oparty na G1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przewidywanie G3 za pomocą innych zmiennych oraz bez G1 i G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df[grades_df['G3'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cieżko jest nie zdobyć żadnego punktu na egazminie, zakładamy, że te osoby nie podeszły i nie można przewidzieć ilości punktów, usuwamy rekordy  z ramki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df = grades_df[grades_df['G3'] != 0]\n",
    "\n",
    "grades_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " W naszej ramce mamy też dużo zmienncyh kategorycznych, zakodujmy je, żeby usprawnić działanie modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['school', 'sex', 'address', 'famsize', 'Mjob', 'Fjob', 'reason', 'guardian', 'Pstatus', 'sex', 'school']\n",
    "bin_cols = ['famsup', 'activities', 'nursery', 'internet', 'romantic', 'higher', 'paid', 'schoolsup']\n",
    "\n",
    "grades_df_new = grades_df.drop(columns = cat_cols)\n",
    "grades_df_new = grades_df.drop(columns = bin_cols)\n",
    "\n",
    "for i in cat_cols:\n",
    "    means = grades_df.groupby(i)['G3'].mean()\n",
    "    grades_df_new[i] = grades_df[i].map(means)\n",
    "    \n",
    "for i in bin_cols:\n",
    "    encoder = ce.OrdinalEncoder(mapping = [{'col': i, 'mapping': {'yes': 1, 'no': 0}},])\n",
    "    grades_df_new[i] = encoder.fit_transform(grades_df)[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pogrupujmy rezultat G3 w przedział, aby nie trzeba było przewidywać dokłądniej liczby - zadanie będzie prostsze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['failed', 'weak', 'ok', 'good', 'excellent']\n",
    "\n",
    "grades_df_new['result'] = pd.cut(grades_df['G3'], bins=[-1, 9, 11, 13, 15, 21], labels = names)\n",
    "\n",
    "sns.countplot(grades_df_new['result'], order = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funkcja liczby accuracy dla 4 modeli i za pomocą xgboost wybiera najważniejsze cechy\n",
    "\n",
    "def modelScores(X, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    importance = pd.DataFrame()\n",
    "    importance['col'] = X.columns \n",
    "    importance['xgb'] = 0\n",
    "\n",
    "    model_xgb = xgb.XGBClassifier(\n",
    "                    max_depth=4\n",
    "                    ,learning_rate=0.2\n",
    "                    ,reg_lambda=1\n",
    "                    ,n_estimators=150\n",
    "                    ,subsample = 0.9\n",
    "                    ,colsample_bytree = 0.9)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "\n",
    "    #print(model_xgb.feature_importances_)\n",
    "    #print(sum(model_xgb.feature_importances_))\n",
    "    #print(len(model_xgb.feature_importances_))\n",
    "    #print(grades_df_new.shape)\n",
    "\n",
    "    importance['xgb'] = importance['xgb'] + model_xgb.feature_importances_ / 100\n",
    "    importance = importance.sort_values(axis=0, ascending=False, by='xgb')\n",
    "    #print('Top 10 features:')\n",
    "    #print(importance.iloc[:, 1:])\n",
    "    print(importance.reset_index().drop('index', axis = 1))\n",
    "    \n",
    "    print(f'xgboost accuarcy: {model_xgb.score(X_test,y_test)}')\n",
    "    \n",
    "    modelLR = LogisticRegression(random_state=1, max_iter=100000)\n",
    "    modelLR.fit(X_train, y_train)\n",
    "    y_hat = modelLR.predict(X_test)\n",
    "    print(f'Logistic Regression accuracy: {accuracy_score(y_test, y_hat)}')\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=188,\n",
    "                                  max_depth=5,\n",
    "                                  min_samples_split = 7, \n",
    "                                  max_features = len(X_train.columns),\n",
    "                                  random_state=0,\n",
    "                                  n_jobs = 15)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    print(f'RandomForestClassifier accuracy: {model_rf.score(X_test,y_test)}')\n",
    "    \n",
    "    model1 = DecisionTreeClassifier(random_state=1)\n",
    "    clf = BaggingClassifier(base_estimator=model_rf,\n",
    "                        n_estimators=100, random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(f'DecisionTreeClassifier accuracy: {clf.score(X_test,y_test)}')\n",
    "    \n",
    "    return importance['col'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new.drop(['G3', 'result'], axis = 1)\n",
    "Y = grades_df_new['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = modelScores(X, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new[cols]\n",
    "Y = grades_df_new['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "modelScores(X, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new.drop(['G3', 'result'], axis = 1)\n",
    "Y = grades_df_new['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki gorsze niż dla prostej regresji liniowej.\n",
    "\n",
    "Stworzylismy prosty model opierający sięn a G1 i G2, spróbujmy teraz bez tych atrybutów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_df_new = grades_df_new.drop(columns = ['G1', 'G2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przewidywanie przedziału oceny za pomocą wszystkich kolumn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new.drop(['G3', 'result'], axis = 1)\n",
    "Y = grades_df_new['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = modelScores(X, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przewidywanie przedziału oceny za pomocą najważnijeszych kolumn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new[cols]\n",
    "Y = grades_df_new['result']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "modelScores(X, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przewidywanie dokładnej oceny za pomocą wszystkich kolumn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new.drop(['G3', 'result'], axis = 1)\n",
    "Y = grades_df_new['G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "cols = modelScores(X, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przewidywanie dokładnej oceny za pomocą najważnieszych kolumn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = grades_df_new[cols]\n",
    "Y = grades_df_new['G3']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.3, random_state=42)\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)\n",
    "modelScores(X, X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
