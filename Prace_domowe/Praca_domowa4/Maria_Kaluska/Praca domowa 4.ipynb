{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "narrow-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-pendant",
   "metadata": {},
   "source": [
    "# Zbiór danych apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "resistant-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"apartments.csv\", index_col=False)\n",
    "df = df.drop(columns=['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-showcase",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m2.price</th>\n",
       "      <th>construction.year</th>\n",
       "      <th>surface</th>\n",
       "      <th>floor</th>\n",
       "      <th>no.rooms</th>\n",
       "      <th>district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5897</td>\n",
       "      <td>1953</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Srodmiescie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1818</td>\n",
       "      <td>1992</td>\n",
       "      <td>143</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Bielany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3643</td>\n",
       "      <td>1937</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Praga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3517</td>\n",
       "      <td>1995</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Ochota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3013</td>\n",
       "      <td>1992</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Mokotow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   m2.price  construction.year  surface  floor  no.rooms     district\n",
       "0      5897               1953       25      3         1  Srodmiescie\n",
       "1      1818               1992      143      9         5      Bielany\n",
       "2      3643               1937       56      1         2        Praga\n",
       "3      3517               1995       93      7         3       Ochota\n",
       "4      3013               1992      144      6         5      Mokotow"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "speaking-fifteen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   m2.price           1000 non-null   int64 \n",
      " 1   construction.year  1000 non-null   int64 \n",
      " 2   surface            1000 non-null   int64 \n",
      " 3   floor              1000 non-null   int64 \n",
      " 4   no.rooms           1000 non-null   int64 \n",
      " 5   district           1000 non-null   object\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 47.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "finished-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['m2.price'])\n",
    "y = df['m2.price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Srodmiescie', 'Bielany', 'Praga', 'Ochota', 'Mokotow', 'Ursus',\n",
       "       'Zoliborz', 'Wola', 'Bemowo', 'Ursynow'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['district'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baking-extension",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\marys\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "X = ce.OneHotEncoder(cols=['district']).fit_transform(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inner-moscow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>construction.year</th>\n",
       "      <th>surface</th>\n",
       "      <th>floor</th>\n",
       "      <th>no.rooms</th>\n",
       "      <th>district_1</th>\n",
       "      <th>district_2</th>\n",
       "      <th>district_3</th>\n",
       "      <th>district_4</th>\n",
       "      <th>district_5</th>\n",
       "      <th>district_6</th>\n",
       "      <th>district_7</th>\n",
       "      <th>district_8</th>\n",
       "      <th>district_9</th>\n",
       "      <th>district_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992</td>\n",
       "      <td>143</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1937</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>93</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992</td>\n",
       "      <td>144</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   construction.year  surface  floor  no.rooms  district_1  district_2  \\\n",
       "0               1953       25      3         1           1           0   \n",
       "1               1992      143      9         5           0           1   \n",
       "2               1937       56      1         2           0           0   \n",
       "3               1995       93      7         3           0           0   \n",
       "4               1992      144      6         5           0           0   \n",
       "\n",
       "   district_3  district_4  district_5  district_6  district_7  district_8  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           1           0           0           0           0           0   \n",
       "3           0           1           0           0           0           0   \n",
       "4           0           0           1           0           0           0   \n",
       "\n",
       "   district_9  district_10  \n",
       "0           0            0  \n",
       "1           0            0  \n",
       "2           0            0  \n",
       "3           0            0  \n",
       "4           0            0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "durable-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f'RMSE: {round(rmse, 4)}')\n",
    "    print(f'R squared: {round(r2_score(y_true, y_pred), 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "typical-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "def print_results_clf(y_true, y_pred):\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print(f'F1 score: {round(f1, 4)}')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {round(accuracy, 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-robin",
   "metadata": {},
   "source": [
    "# Model bez normalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "absent-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "permanent-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = svm.SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "unknown-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, train_size=0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "overhead-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extensive-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "tropical-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 974.3631\n",
      "R squared: -0.0127\n"
     ]
    }
   ],
   "source": [
    "y_pred = svr.predict(X_test)\n",
    "print_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-hacker",
   "metadata": {},
   "source": [
    "# Normalizacja\n",
    "Znormalizujemy kolumny `contruction.year`, `surface`, `floor` oraz `no.rooms`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-teaching",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "digital-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impressive-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 949.4816\n",
      "R squared: 0.0383\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVR())\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-egypt",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ranging-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 949.891\n",
      "R squared: 0.0375\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), svm.SVR())\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-jacksonville",
   "metadata": {},
   "source": [
    "Widzimy, że normalizacja danych rzeczywiście wpływa korzystnie na efektywność modelu. Jednak nie jest to duża różnica.\n",
    "## Random Search\n",
    "Początkowo przeprowadzimy random search dla kernelu `rbf`.\n",
    "Następnie sprawdzimy ten model dla innych kerneli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "higher-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "graphic-botswana",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gamma': [0.01, 0.1, 1, 10],\n",
    "    'C': [1, 10, 100, 1000],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "random_search = RandomizedSearchCV(svm.SVR(), params, n_iter=10)\n",
    "pipe = make_pipeline(MinMaxScaler(), \n",
    "                     random_search)\n",
    "search = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sharp-egypt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'gamma': 0.01, 'C': 1000}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "continental-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVR(kernel='rbf',\n",
    "                                            gamma=0.01,\n",
    "                                            C=1000))\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "infectious-schema",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 342.9967\n",
      "R squared: 0.8745\n"
     ]
    }
   ],
   "source": [
    "print_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-russia",
   "metadata": {},
   "source": [
    "Teraz sprawdzimy czy model z kernelem wielomianowym radzi sobie lepiej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "outer-sector",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gamma': ['scale'],\n",
    "    'degree': [ 3, 4, 6, 7, 8, 10, 12, 15, 20, 25, 30],\n",
    "    'kernel': ['poly']\n",
    "}\n",
    "random_search = GridSearchCV(svm.SVR(), params, scoring='r2', cv=5)\n",
    "pipe = make_pipeline(MinMaxScaler(), \n",
    "                     random_search)\n",
    "search = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ceramic-hammer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'degree': 30, 'gamma': 'scale', 'kernel': 'poly'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "clean-liability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(degree=30, kernel='poly')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "actual-turkish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 132553.4727\n",
      "R squared: -18741.9333\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVR(kernel='poly',\n",
    "                                            degree=30, gamma='scale'))\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-angola",
   "metadata": {},
   "source": [
    "## Wnioski\n",
    "Na danych testowych błąd jest ogromny, wnioskuję z tego, że tak wysoki stopień wielomianu powoduje znaczący overfitting.\n",
    "Z racji tego, że danych jest mało spróbuję jeszcze raz przeprowadzić strojenie parametrów tym razem na niższych stopniach wielomianu i z krosswalidacją dwukrotną. \n",
    "\n",
    "Aby zmniejszyć overfitting spróbuję zwiększyć parametr `C` odpowiadający za regularyzację."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "classical-monster",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'gamma': ['scale'],\n",
    "    'degree': [ 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],\n",
    "    'kernel': ['poly'],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "random_search = RandomizedSearchCV(svm.SVR(), params, scoring='r2', cv=2)\n",
    "pipe = make_pipeline(MinMaxScaler(), \n",
    "                     random_search)\n",
    "search = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "applied-microwave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'poly', 'gamma': 'scale', 'degree': 3, 'C': 1000}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "diagnostic-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 165.1161\n",
      "R squared: 0.9709\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVR(kernel='poly',\n",
    "                                            degree=3, gamma='scale', C=1000))\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "print_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-headquarters",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "Wynik przewyższył moje oczekiwania. Metryka $R^2$ jest bardzo bliska 1 co oznacza, że model jest dobry.\n",
    "\n",
    "Porównując SVR z innymi modelami widzę, że strojenie parametrów w przypadku tego modelu jest kluczowe. Model z niedobranymi parametrami do niczego się nie nadawał.\n",
    "\n",
    "**Wnioski**\n",
    "1. W trakcie uczenia modelu dane należy znormalizować. W tym zadaniu minimalnie lepiej poradził sobie MinMaxScaler. \n",
    "2. Należy unikać zbyt wysokich stopni wielomianu, gdyż prowadzi to do overfittingu.\n",
    "3. Warto dostosowywać pod siebie parametr C odpowiadający za regularyzację.\n",
    "4. Dobrym pomysłem jest przetestowanie różnych kerneli."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-spouse",
   "metadata": {},
   "source": [
    "# Model dla zbioru heart\n",
    "Poniżej skorzystamy z SVM dla problemu klasyfikacji.\n",
    "Opis danych:\n",
    "- age\n",
    "- sex\n",
    "- chest pain type (4 values)\n",
    "- resting blood pressure\n",
    "- serum cholestoral in mg/dl\n",
    "- fasting blood sugar > 120 mg/dl\n",
    "- resting electrocardiographic results (values 0,1,2)\n",
    "- maximum heart rate achieved\n",
    "- exercise induced angina\n",
    "- oldpeak = ST depression induced by exercise relative to rest\n",
    "- the slope of the peak exercise ST segment\n",
    "- number of major vessels (0-3) colored by flourosopy\n",
    "- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "neural-accreditation",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart = pd.read_csv('heart.csv')\n",
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "earlier-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "heart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "human-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = heart.drop(columns=['target'])\n",
    "y_ = heart.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "still-insight",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-alabama",
   "metadata": {},
   "source": [
    "Mamy do czynienia z klasyfikacja binarną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "leading-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, y_, test_size=0.1, train_size=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-electric",
   "metadata": {},
   "source": [
    "## Bez normalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "general-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7179\n",
      "Accuracy: 0.6452\n"
     ]
    }
   ],
   "source": [
    "svc = svm.SVC()\n",
    "svc.fit(X_train_, y_train_)\n",
    "y_pred = svc.predict(X_test_)\n",
    "print_results_clf(y_test_, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-prayer",
   "metadata": {},
   "source": [
    "## Po normalizacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "major-kinase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8387\n",
      "Accuracy: 0.8387\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVC())\n",
    "pipe.fit(X_train_, y_train_)\n",
    "y_pred = pipe.predict(X_test_)\n",
    "print_results_clf(y_test_, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thirty-cologne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8\n",
      "Accuracy: 0.8065\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), svm.SVC())\n",
    "pipe.fit(X_train_, y_train_)\n",
    "y_pred = pipe.predict(X_test_)\n",
    "print_results_clf(y_test_, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constant-quarterly",
   "metadata": {},
   "source": [
    "Ponownie normalizacja okazała się  korzystna. Tym razem miała większe znaczenie.  Lepiej sprawdziła się normalizacja przy pomocy MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-proposal",
   "metadata": {},
   "source": [
    "## Random Search i Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "artistic-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel': ['rbf'],\n",
    "    'gamma': [0.01, 0.02, 0.05, 0.1, 1, 2, 5, 'scale', 'auto'] ,\n",
    "    'C': [0.1, 1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(svm.SVC(), params, cv=3, n_iter=20, scoring='accuracy')\n",
    "pipe = make_pipeline(MinMaxScaler(), rand_search)\n",
    "search = rand_search.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "increasing-denver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'gamma': 0.05, 'C': 10}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "innocent-engagement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8125\n",
      "Accuracy: 0.8065\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVC(kernel='rbf', gamma=0.05, C=10))\n",
    "pipe.fit(X_train_, y_train_)\n",
    "y_pred = pipe.predict(X_test_)\n",
    "print_results_clf(y_test_, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-continent",
   "metadata": {},
   "source": [
    "Wynik trochę się pogorszył."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fresh-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'kernel': ['poly'],\n",
    "    'gamma': ['scale'],\n",
    "    'degree': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "rand_search = RandomizedSearchCV(svm.SVC(), params, cv=2, scoring='accuracy')\n",
    "pipe = make_pipeline(MinMaxScaler(), rand_search)\n",
    "search = rand_search.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "chicken-circus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'poly', 'gamma': 'scale', 'degree': 4, 'C': 1000}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "configured-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8\n",
      "Accuracy: 0.8065\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(MinMaxScaler(), svm.SVC(gamma='scale', degree=4, C=1000, kernel='poly'))\n",
    "pipe.fit(X_train_, y_train_)\n",
    "y_pred = pipe.predict(X_test_)\n",
    "print_results_clf(y_test_, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-notice",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "Wyniki dla kernelu `poly` wyszły gorsze niż dla kernelu `rbf`. Ogólnie sam proces strojenia parametrów nie poprawił działania modelu.\n",
    "\n",
    "**Wnioski**\n",
    "1. Ważna jest normalizacja danych.\n",
    "2. Czasem wyniku nie da się poprawić zmieniając tylko parametry."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
