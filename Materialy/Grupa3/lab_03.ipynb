{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klasyfikacja \n",
    "Klasyfikacja to rodzaj algorytmu statystycznego, który przydziela obserwacje statystyczne do klas, bazując na atrybutach tych obserwacji.\n",
    "\n",
    "**Definicja:**\n",
    "Dla danego zbioru danych trenujących $\\{(x_1,y_1),\\ldots,(x_n,y_n)\\}$ algorytm potrafi znaleźć funkcję klasyfikującją $h: X -> Y$, która przydziela obiektowi $x\\in X$ klasę $y \\in Y$.\n",
    "\n",
    "- prawdopodobieństwo aposteriori: $P(Y=i|X)$ *\n",
    "- funkcja klasyfikacyjna przyjmuje postać: $h(X) = argmax_{1,\\ldots,y} P(Y=i|X)$\n",
    "\n",
    "*większość klasyfikatorów modeluje prawdopodobieństwa, wyjątek stanowi SVM\n",
    "\n",
    "Przykłady klasyfikacji:\n",
    "- wykrywanie czy pacjent jest chory na daną chorobę na podstawie wyników badań\n",
    "- klasyfikacja maili jako spam/nie-spam\n",
    "- czy transakcja dokonana na koncie klienta banku to oszustwo/kradzież czy też normalna transakcja\n",
    "- rozpoznawania na obrazu różnych rodzajów zwierząt\n",
    "- rozpoznawanie czy pasażer przeżyje katastrofę na Titanicu\n",
    "\n",
    "**Na potrzeby uproszczenia wyjaśniania w dalszej części labów, skupimy się tylko na klasyfikacji binarnej.**\n",
    "\n",
    "Zajmiemy się zbiorem gdzie klasyfikujemy u pacjentów czy występuje choroba serca czy nie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T15:01:18.130629Z",
     "start_time": "2020-03-07T15:01:18.127672Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T14:45:39.531710Z",
     "start_time": "2020-03-07T14:45:39.518696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11  Present     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61   Absent     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28  Present     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03  Present     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78  Present     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T14:45:53.174538Z",
     "start_time": "2020-03-07T14:45:53.166435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sbp          0.0\n",
       "tobacco      0.0\n",
       "ldl          0.0\n",
       "adiposity    0.0\n",
       "famhist      0.0\n",
       "typea        0.0\n",
       "obesity      0.0\n",
       "alcohol      0.0\n",
       "age          0.0\n",
       "chd          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Szybko sprawdzamy podstawowe cechy danych\n",
    "na_ratio_cols = data.isna().mean(axis=0)\n",
    "na_ratio_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(data['chd'])\n",
    "X = data.drop(['chd','famhist'],axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>Present</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>Present</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>Present</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>214</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.98</td>\n",
       "      <td>31.72</td>\n",
       "      <td>Absent</td>\n",
       "      <td>64</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>182</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.41</td>\n",
       "      <td>32.10</td>\n",
       "      <td>Absent</td>\n",
       "      <td>52</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.72</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>108</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>15.23</td>\n",
       "      <td>Absent</td>\n",
       "      <td>40</td>\n",
       "      <td>20.09</td>\n",
       "      <td>26.64</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>118</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.61</td>\n",
       "      <td>30.79</td>\n",
       "      <td>Absent</td>\n",
       "      <td>64</td>\n",
       "      <td>27.35</td>\n",
       "      <td>23.97</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.82</td>\n",
       "      <td>33.41</td>\n",
       "      <td>Present</td>\n",
       "      <td>62</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sbp  tobacco    ldl  adiposity  famhist  typea  obesity  alcohol  age  \\\n",
       "0    160    12.00   5.73      23.11  Present     49    25.30    97.20   52   \n",
       "1    144     0.01   4.41      28.61   Absent     55    28.87     2.06   63   \n",
       "2    118     0.08   3.48      32.28  Present     52    29.14     3.81   46   \n",
       "3    170     7.50   6.41      38.03  Present     51    31.99    24.26   58   \n",
       "4    134    13.60   3.50      27.78  Present     60    25.99    57.34   49   \n",
       "..   ...      ...    ...        ...      ...    ...      ...      ...  ...   \n",
       "457  214     0.40   5.98      31.72   Absent     64    28.45     0.00   58   \n",
       "458  182     4.20   4.41      32.10   Absent     52    28.61    18.72   52   \n",
       "459  108     3.00   1.59      15.23   Absent     40    20.09    26.64   55   \n",
       "460  118     5.40  11.61      30.79   Absent     64    27.35    23.97   40   \n",
       "461  132     0.00   4.82      33.41  Present     62    14.70     0.00   46   \n",
       "\n",
       "     chd  \n",
       "0      1  \n",
       "1      1  \n",
       "2      0  \n",
       "3      1  \n",
       "4      1  \n",
       "..   ...  \n",
       "457    0  \n",
       "458    1  \n",
       "459    0  \n",
       "460    0  \n",
       "461    1  \n",
       "\n",
       "[462 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T14:52:23.920291Z",
     "start_time": "2020-03-07T14:52:23.911127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11        1     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61        0     55    28.87     2.06   63    1\n",
       "2  118     0.08  3.48      32.28        1     52    29.14     3.81   46    0\n",
       "3  170     7.50  6.41      38.03        1     51    31.99    24.26   58    1\n",
       "4  134    13.60  3.50      27.78        1     60    25.99    57.34   49    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Szybkie ćwiczenie - wykonaj dowolne kodowanie zmiennej kategorycznej\n",
    "cleanup_nums = {\"famhist\":     {\"Present\": 1, \"Absent\": 0}}\n",
    "data = data.replace(cleanup_nums)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sposoby podziału danych\n",
    "- Jak radzić sobie z overfitingiem?\n",
    "- Jakie znacie sposoby podziału danych na treningowe i testowe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](https://media.geeksforgeeks.org/wp-content/cdn-uploads/20190523171258/overfitting_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/\n",
    "\n",
    "## Zbiór treningowy, walidacyjny i testowy¶\n",
    "Prosty podział danych na część, na której uczymy model i na część która służy nam do sprawdzenia jego skuteczności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:50:27.159896Z",
     "start_time": "2020-03-07T17:50:27.154910Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_val, y_val, stratify=y_val, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_test).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(y_test).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:50:52.333567Z",
     "start_time": "2020-03-07T17:50:52.329929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 8) (323, 8) (97, 8) (42, 8)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaki znacie najprostszy klasyfikator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T16:35:17.078577Z",
     "start_time": "2020-03-07T16:35:17.072606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proba: [0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n",
      "y:     [0 1 0 0 0 1 0 0 0 1]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.4742268041237113\n",
      "train : 0.5201238390092879\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='uniform', random_state=42)\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=dc.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestujcie jaki będzie wynik działania algorytmu gdy zmienimy parametr *strategy* (oraz porównać accuracy) - podpowiedź: skorzystaj z dokumentacji funkcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: policzyć accuracy dla baselinu (z inną strategią niż uniform) na train i validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proba: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "y:     [0 0 0 0 0 0 0 0 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6597938144329897\n",
      "train : 0.653250773993808\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='most_frequent', random_state=42)\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=dc.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proba: [0.65325077 0.65325077 0.65325077 0.65325077 0.65325077 0.65325077\n",
      " 0.65325077 0.65325077 0.65325077 0.65325077]\n",
      "y:     [0 0 0 0 0 0 0 0 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6597938144329897\n",
      "train : 0.653250773993808\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='prior', random_state=42)\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=dc.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proba: [1. 0. 0. 1. 1. 1. 1. 0. 1. 0.]\n",
      "y:     [0 1 1 0 0 0 0 1 0 1]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.5567010309278351\n",
      "train : 0.6160990712074303\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=dc.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proba: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "y:     [0 0 0 0 0 0 0 0 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6597938144329897\n",
      "train : 0.653250773993808\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='constant', random_state=42, constant=0 )\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=dc.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proba: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "y:     [1 1 1 1 1 1 1 1 1 1]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.3402061855670103\n",
      "train : 0.34674922600619196\n"
     ]
    }
   ],
   "source": [
    "dc = DummyClassifier(strategy='constant', random_state=42, constant=1 )\n",
    "dc.fit(X_train,y_train)\n",
    "y_proba = dc.predict_proba(X_val)\n",
    "y_hat = dc.predict(X_val)\n",
    "print(\"proba: \" + str(y_proba[0:10,0]) + '\\ny:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=dc.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jakieś inne proste klasyfikatory?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresja logistyczna - czemu by nie prognozować prawdopodobieństwa za pomocą regresji liniowej?\n",
    "\n",
    "**Przypomnienie:** uogólniony model liniowy: $y_{i}=\\beta _{0}1+\\beta _{1}x_{i1}+\\cdots +\\beta _{p}x_{ip} = x^T \\beta$\n",
    "\n",
    "- Jaki jest podstawowy problem z wykorzystaniem regresji do modelowania prawdopodobieństwa?\n",
    "- Jakie macie propozycje rozwiązania tego problemu?\n",
    "\n",
    "$odds = \\frac{P(Y=1|X)}{P(Y=0|X)} = \\frac{p}{1-p}$ $\\in (0,\\infty)$\n",
    "\n",
    "$\\log({odds}) \\in (-\\infty, \\infty)$\n",
    "\n",
    "Co pozwala nam modelować powyższe równanie dzięki regresji liniowej, po przekształceniu równania, uzyskujemy prawdopodobieństwo sukcesu:\n",
    "\n",
    "$x^T \\beta = \\log({\\frac{p}{1-p}}) \\Rightarrow p = \\frac{1}{1+\\exp({-x^T \\beta})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281070/linear_vs_logistic_regression_edxw03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.datacamp.com/community/tutorials/understanding-logistic-regression-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T15:17:06.286476Z",
     "start_time": "2020-03-07T15:17:06.227772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [1 0 0 1 0 0 0 1 0 1]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6288659793814433\n",
      "train : 0.7213622291021672\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=lr.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: policzyć accuracy dla logita z l1, l2, i bez regularyzacji na train i validation\n",
    "# porównać z baselinem \n",
    "# (porównanie accuracy na trainie i devie 2 baselinów i 3 modeli (l1, l2, i bez regularyzacji)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [1 0 0 1 0 0 0 1 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6391752577319587\n",
      "train : 0.7244582043343654\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, penalty='l1',solver='liblinear')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=lr.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [0 0 0 1 0 0 0 1 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.7010309278350515\n",
      "train : 0.7244582043343654\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, penalty='l1',solver='saga')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=lr.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [0 0 0 1 0 0 0 1 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6907216494845361\n",
      "train : 0.718266253869969\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, penalty='l2',solver='saga')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=lr.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [0 0 0 1 0 0 0 1 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n",
      "validation : 0.6907216494845361\n",
      "train : 0.718266253869969\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, penalty='none',solver='saga')\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "y_hat = lr.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "sum=0\n",
    "for i in range(len(y_hat)):\n",
    "    if y_hat[i]==y_val[i]:\n",
    "        sum+=1\n",
    "accuracy=sum/len(y_hat)\n",
    "print(\"validation : \" + str(accuracy))\n",
    "sum=0\n",
    "y_trained=lr.predict(X_train)\n",
    "for i in range(len(y_trained)):\n",
    "    if y_trained[i]==y_train[i]:\n",
    "        sum+=1\n",
    "accuracy_train=sum/len(y_trained)\n",
    "print(\"train : \" + str(accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Podsumowanie**\n",
    "\n",
    "- Zauważyć można, że poszczególne solvery mają spory wpływ na accuracy i wyniki uczenia modelu\n",
    "- Ogólna tendencja wskazuje, że o ile dla modelów train ma zawsze większe accuracy, to dla baselinów wyniki te są bardzo zbliżone\n",
    "- Modele także wypadają lepiej od baselinów (a przynajmniej po zastosowaniu solvera 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0106575 ,  0.06376262,  0.27532893,  0.01608405,  0.00261298,\n",
       "        -0.10919783,  0.0017442 ,  0.03783187]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.08325448])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jak interpretować wyniki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2348858587744127"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jak się zmieni powyższy wynik gdy zwiększymy wartość czwartej cechy (tj. adiposity) dla pierwszej obserwacji o 1\n",
    "\n",
    "#solution\n",
    "experiment=X_val.iloc[0,:]\n",
    "experiment[3]=experiment[3]+1\n",
    "np.log(lr.predict_proba(experiment.values.reshape(1,-1))[0,1]/lr.predict_proba(experiment.values.reshape(1,-1))[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dlaczego można było się przewidzieć, że taki właśnie będzie wynik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2348858587744126"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "np.log(lr.predict_proba(X_val)[0,1]/lr.predict_proba(X_val)[0,0])+lr.coef_[0,3]\n",
    "# otrzymano taki sam wynik - nie trzeba było wykonywać metody predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Jaki będzie wynik gdy wektor cech będzie miał tylko zerowe elementy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dlaczego można było się przewidzieć, że taki właśnie będzie wynik?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.47919839])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "1/(1+np.exp(-lr.intercept_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jakie są zalety regresji logistycznej?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drzewo decyzyjne\n",
    "- Jak wykorzystać model drzewa do predykcji klasyfikacji/regresji?\n",
    "- jakie problemy może to generować?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T16:33:36.468292Z",
     "start_time": "2020-03-07T16:33:36.240821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [0 0 0 0 0 0 0 1 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree #export_graphviz\n",
    "## biblioteka poniżej może być problematyczna na Windows\n",
    "#import graphviz\n",
    "\n",
    "tree1 = DecisionTreeClassifier()\n",
    "\n",
    "tree1.fit(X_train,y_train)\n",
    "y_hat = tree1.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))\n",
    "\n",
    "#plt.figure(figsize=(20,20))\n",
    "#splits=tree.plot_tree(tree1, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO spróbujcie wytrenować model ze zmienionymi parametrami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "Znalezienie równania hiperpłaszczyzny, która najlepiej dzieli nasz zbiór danych na klasy.\n",
    "\n",
    "**Uwaga: w przypadku SVM nie modelujemy prawdopodobieństwa przynależności do danej klasy - domyślnym wyjściem jest informacja o konkretnej klasie**\n",
    "- Co jeżeli nie istnieje taka płaszczyzna?\n",
    "- Co jeżeli nasze dane nie są separowalne liniowo, tylko np. radialnie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://upload.wikimedia.org/wikipedia/commons/thumb/7/72/SVM_margin.png/300px-SVM_margin.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Support-vector_machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://machine-learning-note.readthedocs.io/en/latest/_images/svm_kernel_trick.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machine-learning-note.readthedocs.io/en/latest/algorithm/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T16:57:59.319024Z",
     "start_time": "2020-03-07T16:57:59.302833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [0 0 0 0 0 0 0 0 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "svm.fit(X_train,y_train)\n",
    "y_hat = svm.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jakie są wady?\n",
    "- trudno dobrać optymalne parametry\n",
    "- metoda wrażliwa na skalowanie danych\n",
    "- długo się \"uczy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naiwny Klasyfikator Bayesowski\n",
    "Jest oparty na założeniu o wzajemnej niezależności zmiennych. Często nie mają one żadnego związku z rzeczywistością i właśnie z tego powodu nazywa się je naiwnymi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/cae70e6035d9ac52c547bc1c666e372063b85324)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mianownik nie zależy od C więc nie będziemy go dalej analizować - skupimy się na liczniku.\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/2d0555690cd428cb6d6a52ea6b6391256125a45c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekurencyjnie obliczenia będą kontynuowane. Teraz pora zrozumieć dokładniej dlaczego występuje słowo \"naiwny\" w nazwie metody.\n",
    "    Zakładamy bowiem że cechy $F_i$ są niezależne czyli ![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/8898f2ee081f407669fdb7a4f60e390615513346)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ostatecznie wzór to: ![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/a5978cc50b1c3d745ad304987a750aeb4a27df5b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pl.wikipedia.org/wiki/Naiwny_klasyfikator_bayesowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:27:54.549246Z",
     "start_time": "2020-03-07T17:27:54.541140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:     [1 1 0 1 0 0 0 1 0 0]\n",
      "y_hat: [0 0 0 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train,y_train)\n",
    "y_hat = nb.predict(X_val)\n",
    "print('y:     ' + str(y_hat[0:10]) + '\\ny_hat: ' + str(y_val[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lepszy sposób na podział danych na zbiory treningowe i testowe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossvalidation\n",
    "- Czy możemy stosować CV dzieląc zbiór, tak by w zbiorze walidacyjnym pozostała tylko jedna obserwacja danych?\n",
    "- Czy sprawdzając performance modelu przez CV, możemy potem nauczyć model na całym zbiorze danych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T17:58:33.491733Z",
     "start_time": "2020-03-07T17:58:33.127377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64285714, 0.73809524, 0.71428571, 0.66666667, 0.78571429,\n",
       "       0.61904762, 0.71428571, 0.71428571, 0.73809524, 0.61904762])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X_train_val=pd.concat((X_train,X_val))\n",
    "y_train_val=np.concatenate((y_train,y_val), axis=0)\n",
    "cross_val_score(lr, X_train_val, y_train_val, scoring='accuracy', cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miary ocen jakości klasyfikatorów\n",
    "- Jakie znacie miary oceny klasyfikatorów?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "$ACC = \\frac{TP+TN}{ALL}$\n",
    "\n",
    "Bardzo intuicyjna miara - ile obserwacji zakwalifikowaliśmy poprawnie.\n",
    "\n",
    "- Jaki jest problem z *accuracy*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision & Recall\n",
    "$PRECISION = \\frac{TP}{TP+FP}= \\frac{TP}{\\text{TOTAL PREDICTED POSITIVE}}$\n",
    "\n",
    "$RECALL = \\frac{TP}{TP+FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score\n",
    "$F1\\_SCORE =\\frac{2*PRECISION*RECALL}{PRECISION+RECALL}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://mathspace.pl/wp-content/uploads/2016/09/ROC-krzywa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mathspace.pl/matematyka/receiver-operating-characteristic-krzywa-roc-czyli-ocena-jakosci-klasyfikacji-czesc-7/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/06/data-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie** - przetestować 3 modele przedstawione dziś na zajęciach i sprawdzić, który jest lepszy na podstawie wyżej wymienionych miar. Należy zastosować kroswalidację."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
