{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consistent-waterproof",
   "metadata": {},
   "source": [
    "# WUM - projekt 1 - feature engineering, wstępne modelowanie\n",
    "**Przewidywanie oceny końcoworocznej w portugalskich szkołach** \n",
    "\n",
    "**Mikołaj Spytek, Artur Żółkowski**\n",
    "\n",
    "W tej części pracy nad projektem przygotowaliśmy odpowiednio zmienne, aby można było za ich pomocą nauczyć modele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None, \"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download the data\n",
    "r = requests.get('https://api.apispreadsheets.com/api/dataset/school-grades/')\n",
    "data = r.json()\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-edmonton",
   "metadata": {},
   "source": [
    "W ramce danych, na której pracujemy znajdują się kolumny `G1` i `G2`, oznaczające oceny z poprzednich semestrów. Zdecydowaliśmy, że nie będziemy ich wykorzystywać, do predykcji zmiennej `G3`, gdyż taki model jest mało użyteczny, a uzyskanie dobrych wyników nie jest trudne. Postanowiliśmy jednak, że użyjemy tych zmiennych, aby wyznaczyć pewnego rodzaju baseline - jeśli za pomocą złożonego modelu korzystającego z innych zmiennych uda nam się osiągnąć wynik, jaki dostajemy na prostym modelu, ale ze zmiennymi `G1` i `G2`, to będziemy zadowoleni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# model wytrenowany tylko na zmiennych G1, G2\n",
    "X_simple = pd.DataFrame()\n",
    "y_simple = pd.DataFrame()\n",
    "\n",
    "X_simple[[\"G1\"]] = df[[\"G1\"]].copy()\n",
    "X_simple[[\"G2\"]] = df[[\"G2\"]].copy()\n",
    "y_simple[[\"G3\"]] = df[[\"G3\"]].copy()\n",
    "\n",
    "\n",
    "X_simple_train, X_simple_test, y_simple_train, y_simple_test = train_test_split(X_simple, y_simple, test_size = 0.2, random_state=42)\n",
    "\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_simple_train, y_simple_train)\n",
    "simple_pred = simple_model.predict(X_simple_test)\n",
    "\n",
    "simple_rmse = np.sqrt(mean_squared_error(y_simple_test, simple_pred))\n",
    "\n",
    "print(\"RMSE (of simple model with G1 and G2) = {:.3f}\".format(simple_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-attitude",
   "metadata": {},
   "source": [
    "Naszym kolejnym pomysłem było sprawdzenie, jakie wyniki będzie osiągał model wytrenowany na wszystkich dostępnych zmiennych, oprócz wyżej wymienionych kolumn. Nie można jednak było ich użyć od razu. Część z nich jest typu kategorycznego, i wymaga zakodowania. Niektóre zaś są podane w skali od 1 do 5 - więc przeskalujemy je dzieląc przez maksimum tak, aby przyjmowały wartości z zakresu $[0, 1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "enc = OneHotEncoder(drop=\"if_binary\", sparse=False)\n",
    "\n",
    "categorical_variables = enc.fit_transform(df.iloc[:, [0,1,3,4,5,8,9,10,11,15,16,17,18,19,20,21,22]])\n",
    "\n",
    "variables_1_5 = df.iloc[:, [6,7,12,13,23,24,25,26,27,28,29]] / 5\n",
    "\n",
    "not_changed = df.iloc[:, [2,14,30]]\n",
    "\n",
    "temp = np.append(categorical_variables, variables_1_5, axis=1)\n",
    "X_all = np.append(temp, not_changed, axis=1)\n",
    "y = df[\"G3\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "\n",
    "s = svm.SVR()\n",
    "\n",
    "s.fit(X_train, y_train)\n",
    "s_predict = s.predict(X_test)\n",
    "\n",
    "s_rmse = np.sqrt(mean_squared_error(y_test, s_predict))\n",
    "\n",
    "gnb = BernoulliNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb_predict = gnb.predict(X_test)\n",
    "\n",
    "gnb_rmse = np.sqrt(mean_squared_error(y_test, gnb_predict))\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "ada_pred = ada.predict(X_test)\n",
    "\n",
    "ada_rmse = np.sqrt(mean_squared_error(y_test, ada_pred))\n",
    "\n",
    "\n",
    "print(\"RMSE (of linear regression) = {:.3f}\".format(lr_rmse))\n",
    "print(\"RMSE (of random forest) = {:.3f}\".format(rf_rmse))\n",
    "print(\"RMSE (of SVR) = {:.3f}\".format(s_rmse))\n",
    "print(\"RMSE (of bernouli naive bayes) = {:.3f}\".format(gnb_rmse))\n",
    "print(\"RMSE (of adaboost) = {:.3f}\".format(ada_rmse))\n",
    "\n",
    "\n",
    "## Powinniśmy jeszcze skorzysta z jakiegś prostego baselinu, czy te wyniki są w ogóle dobre - niech to będzie średnia\n",
    "\n",
    "sr = y_train.mean()\n",
    "y_baseline = [sr for i in range(len(y_test))]\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_baseline))\n",
    "print(\"RMSE (of baseline) = {:.3f}\".format(rmse_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-interference",
   "metadata": {},
   "source": [
    "Jak widzimy osiągamy całkiem dobre wyniki po tak podstawowym feature engineeringu. Postanowiliśmy jednak sprawdzić, czy na mniejszej ilości cech nie osiągniemy lepszych wyników. Usunęliśmy zmienne mocno skorelowane (przyjrzeliśmy się macierzy korelacji z naszego EDA) oraz niektóre, które naszym zdaniem mają niewielki wpływ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olympic-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(drop=\"if_binary\", sparse=False)\n",
    "\n",
    "categorical_variables = enc.fit_transform(df.iloc[:, [0,1,5,9,17,19,20,21]])\n",
    "\n",
    "variables_1_5 = df.iloc[:, [6,7,12,13,25,28,29]] / 5\n",
    "\n",
    "not_changed = df.iloc[:, [2,30]]\n",
    "\n",
    "temp = np.append(categorical_variables, variables_1_5, axis=1)\n",
    "X_all = np.append(temp, not_changed, axis=1)\n",
    "y = df[\"G3\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_train,y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "lr_rmse = np.sqrt(mean_squared_error(y_test, lr_pred))\n",
    "\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
    "\n",
    "s = svm.SVR()\n",
    "\n",
    "s.fit(X_train, y_train)\n",
    "s_predict = s.predict(X_test)\n",
    "\n",
    "s_rmse = np.sqrt(mean_squared_error(y_test, s_predict))\n",
    "\n",
    "gnb = BernoulliNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "gnb_predict = gnb.predict(X_test)\n",
    "\n",
    "gnb_rmse = np.sqrt(mean_squared_error(y_test, gnb_predict))\n",
    "\n",
    "ada = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "ada_pred = ada.predict(X_test)\n",
    "\n",
    "ada_rmse = np.sqrt(mean_squared_error(y_test, ada_pred))\n",
    "\n",
    "print(\"RMSE (of linear regression with less variables) = {:.3f}\".format(lr_rmse))\n",
    "print(\"RMSE (of random forest with less variables) = {:.3f}\".format(rf_rmse))\n",
    "print(\"RMSE (of SVR) = {:.3f}\".format(s_rmse))\n",
    "print(\"RMSE (of bernouli naive bayes) = {:.3f}\".format(gnb_rmse))\n",
    "print(\"RMSE (of adaboost) = {:.3f}\".format(ada_rmse))\n",
    "\n",
    "\n",
    "sr = y_train.mean()\n",
    "y_baseline = [sr for i in range(len(y_test))]\n",
    "rmse_baseline = np.sqrt(mean_squared_error(y_test, y_baseline))\n",
    "print(\"RMSE (of baseline) = {:.3f}\".format(rmse_baseline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-calendar",
   "metadata": {},
   "source": [
    "Po takich modyfikacjach otrzymaliśmy trochę lepszy wynik przy prostych modelach, przynajmniej patrząc na tę miarę, którą wybraliśmy. Na modelach bardziej skomplikowanych miara błędu pozostaje na podobnym poziomie\n",
    "\n",
    "# Część klasyfikacyjna\n",
    "\n",
    "W poleceniu zadania (na repo przedmiotu) znaleźliśmy informację, że pierwszy projekt ma dotyczyć klasyfikacji. Można to zadanie potraktować jako 20-sto klasową klasyfikację, lecz nie jest to naszym zdaniem najlepsze podejście do tego problemu. Patrząc na inne tematy tego projektu klasyfikacja w tamtych problemach jest binarna, i bardziej naturalna.\n",
    "\n",
    "Problemem przy traktowaniu tego jako klasyfikację, jest również miara, której mielibyśmy używać do ewaluacji modelu. Gdyby miało to być po prostu accuracy, to pomyłka oceny o 1 traktowana by była tak samo, jak pomyłka o 19. \n",
    "\n",
    "Postanowiliśmy przewidywać czy dana osoba zdała, tzn. czy ocena jest `>=10`.\n",
    "\n",
    "Na tym etapie dodaliśmy kolejne techniki feature engineeringu. Zmienne które były w skali od 1 do 5, przeskalowaliśmy dzieląc przez 5, tak, aby dostawać wartości z przedziału $[0,1]$\n",
    "\n",
    "Stwierdziliśmy też, że warto dodać zmienną, która mówi o tym, czy ktoś wcześniej nie zdał. Oraz taką, która określa, czy ktoś ma więcej niż 5 nieobecności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pass']= np.where(df['G3']<10, 0, 1)\n",
    "df['Pedu'] = df['Fedu'] + df['Medu']\n",
    "df[\"genrel\"] = df[\"sex\"]+df[\"romantic\"]\n",
    "df[[\"Pedu\"]]  = df[[\"Pedu\"]] / 5\n",
    "df[[\"studytime\"]]  = df[[\"studytime\"]] / 5\n",
    "df[[\"age\"]] = df[[\"age\"]] # /22\n",
    "df[[\"health\"]] = df[[\"health\"]]/5\n",
    "df[[\"goout\"]] = df[[\"goout\"]]/5\n",
    "df[[\"Dalc\"]] = df[[\"Dalc\"]]/5\n",
    "\n",
    "df[[\"absences\"]] = df[[\"absences\"]]/df['absences'].max()\n",
    "df[[\"absenc\"]] = np.where(df['absences']<5, 0, 1)\n",
    "\n",
    "fail = pd.DataFrame([(1 if a > 0 else 0) for a in df['failures']], columns=[\"fail\"])\n",
    "\n",
    "df = df.join(fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comic-absorption",
   "metadata": {},
   "source": [
    "Następnie wybraliśmy według nas najistotniejsze zmienne dzieląc je na kategoryczne i numeryczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [\"Mjob\", \"higher\", \"internet\", \"romantic\", \"address\", \"reason\", \n",
    "                \"activities\", \"famsup\", \"schoolsup\", \"school\"]\n",
    "num_features = [\"Pedu\", \"health\", \"studytime\", \"Dalc\", \"Walc\", \"traveltime\", \"freetime\", \"goout\", \"age\", \"fail\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and predicted value\n",
    "features = num_features + cat_features\n",
    "X = df.drop([\"pass\"], axis=1)[features]\n",
    "y = df[\"pass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-mileage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess numerical feats:\n",
    "num_transformer = SimpleImputer(strategy=\"constant\")\n",
    "\n",
    "# Preprocessing for categorical features:\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"Unknown\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical features:\n",
    "preprocessor = ColumnTransformer(transformers=[(\"num\", num_transformer, num_features),\n",
    "                                               (\"cat\", cat_transformer, cat_features)],\n",
    "                                remainder = 'passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaptive-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_enh = RandomForestClassifier(n_estimators=10,\n",
    "                               max_features=0.4,\n",
    "                               min_samples_split=2,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=33)\n",
    "\n",
    "model_pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', rf_model_enh)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2, random_state=42)\n",
    "\n",
    "model_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-sheriff",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-elements",
   "metadata": {},
   "source": [
    "Po tak dobranych zmiennych wytrenowaliśmy model Random Forest Classifier. Jak widizmy, udało nam się osiągnąć dobry rezultat przy accuracy wynoszącym ponad 89%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-absolute",
   "metadata": {},
   "source": [
    "Następnie korzystająć z biblioteki dalex chcieliśmy sprawdzić czy nasz model nie jest zvyt stronniczy, lub czy nie występują w nim żadne zmienne dominujące mogące samodzielnie zdecydować o wartości predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "\n",
    "explainer = dx.Explainer(model_pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-ethernet",
   "metadata": {},
   "source": [
    "Przeanalizujmy teraz przykładową predykcję 1 i 0 (zdał, nie zdał). Weźmy zatem pierwsze wystąpienia tych wartości z naszego zbioru testowego (odpowiednio obserwacja 220 i 131)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_1 = explainer.predict_parts(X_test.iloc[1,:])\n",
    "pp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-basis",
   "metadata": {},
   "source": [
    "Jak możemy zauważyć nasz model prawidłowo przewidział wartość predykcyjną. Nie widzimy tutaj żdanych dominujących czynników wpływających na wynik. W tym przypadku największe znaczenie miało to, że uczeń nie miał wcześniejszych porażek oraz to, że chodził do szkoły oznaczonej jako GP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_0 = explainer.predict_parts(X_test.iloc[7,:])\n",
    "pp_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-macintosh",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_0.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-rebel",
   "metadata": {},
   "source": [
    "Również w drugim przypadku algorytm poprawnie rozpoznał czy uczeń zda. W tym przypadku największe znaczenie miała poprzednia porażka oraz brak chęci dalszej edukacji."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
