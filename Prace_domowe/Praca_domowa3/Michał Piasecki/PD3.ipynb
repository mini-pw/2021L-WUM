{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "australia = pd.read_csv('australia.csv')\n",
    "australia.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podział na treningowy i testowy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = australia['RainTomorrow']\n",
    "X = australia.drop(columns=['RainTomorrow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_accuracy(y_received,y_real):\n",
    "    sum_false = np.sum(np.abs(y_received - y_real))\n",
    "    length = len(y_received)\n",
    "    accuracy = ((length - sum_false) / len(y_received)) * 100 \n",
    "    print (f\"Accuracy is: {round(accuracy,3)} %\")\n",
    "def model_precision(y_received, y_real):\n",
    "    true_positive = np.sum(y_received[np.where(y_received == 1) and np.where(y_real == 1)])\n",
    "    true = np.sum(y_real)\n",
    "    precision = true_positive / true\n",
    "    print(f\"Precision is {round(precision, 3)} %\")\n",
    "def model_recall(y_received, y_real):\n",
    "    true_positive = np.sum(y_received[np.where(y_received == 1) and np.where(y_real == 1)])\n",
    "    false_negative = np.sum(y_received[np.where(y_received == 0) and np.where(y_real == 1)])\n",
    "    recall = true_positive / (true_positive + false_negative)\n",
    "    print(f\"Recall  is {round(recall, 3)} %\")\n",
    "\n",
    "    \n",
    "def model_evaluation(y_received, y_real):\n",
    "    print(\"Evaluation\")\n",
    "    model_accuracy(y_received, y_real)\n",
    "    model_precision(y_received, y_real)\n",
    "    model_recall(y_received, y_real)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_frequent = DummyClassifier(strategy = 'most_frequent', random_state=123)\n",
    "dummy_frequent.fit(X_train, y_train)\n",
    "results_dummy_frequent = dummy_frequent.predict(X_test)\n",
    "\n",
    "dummy_stratified = DummyClassifier(strategy = 'stratified', random_state=123)\n",
    "dummy_stratified.fit(X_train, y_train)\n",
    "results_dummy_stratified = dummy_stratified.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dummy with strategy: frequent\")\n",
    "model_evaluation(results_dummy_frequent,y_test)\n",
    "print(\"Dummy with strategy: stratified\")\n",
    "model_evaluation(results_dummy_stratified,y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_liblinear = LogisticRegression(solver = 'liblinear' , max_iter=1000, random_state= 123)\n",
    "lr_liblinear.fit(X_train, y_train)\n",
    "results_regression_liblinear = lr_liblinear.predict(X_test)\n",
    "lr_newton = LogisticRegression(solver = 'newton-cg', max_iter = 1000, random_state = 123)\n",
    "lr_newton.fit(X_train, y_train)\n",
    "results_regression_newton = lr_newton.predict(X_test)\n",
    "lr_saga = LogisticRegression(solver = 'saga', max_iter = 1000, random_state = 123)\n",
    "lr_saga.fit(X_train, y_train)\n",
    "results_regresssion_saga = lr_saga.predict(X_test)\n",
    "lr_saga_elastic = LogisticRegression(solver = 'saga', penalty = 'elasticnet', max_iter = 1000, random_state = 123, l1_ratio = 0.8)\n",
    "lr_saga_elastic.fit(X_train, y_train)\n",
    "results_regression_saga_elastic = lr_saga_elastic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic regression: liblinear solver\")\n",
    "model_evaluation(results_regression_liblinear, y_test)\n",
    "print(\"Logistic regression: newton solver\")\n",
    "model_evaluation(results_regression_newton, y_test)\n",
    "print(\"Logistic regression: saga solver\")\n",
    "model_evaluation(results_regresssion_saga, y_test)\n",
    "print(\"Logistic regression:  saga solver with elastic 0.2 l1\")\n",
    "model_evaluation(results_regression_saga_elastic, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,plot_tree #export_graphviz\n",
    "\n",
    "\n",
    "tree_gini = DecisionTreeClassifier()\n",
    "tree_gini.fit(X_train,y_train)\n",
    "results_tree_gini = tree_gini.predict(X_test)\n",
    "\n",
    "tree_entropy = DecisionTreeClassifier(criterion= 'entropy')\n",
    "tree_entropy.fit(X_train, y_train)\n",
    "results_tree_entropy = tree_entropy.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Decision tree: gini\")\n",
    "model_evaluation(results_tree_gini, y_test)\n",
    "print(\"Decision tree: entropy\")\n",
    "\n",
    "model_evaluation(results_tree_entropy, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "results_nb = nb.predict(X_test)\n",
    "print(\"Naive Bayes Classifier\")\n",
    "model_evaluation(results_nb, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wnioski:\n",
    "Sama accuracy nie wystarcza do oceny modelu. Analiza recall + precision wydaje się dobrym rozwiązaniem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
